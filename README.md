# üß¨ Fine-Tuned Medical Reasoning Model (DeepSeek-R1-Distill-Llama-8B)

This project demonstrates the fine-tuning of the **DeepSeek-R1-Distill-Llama-8B** model using **Unsloth** for **medical question answering and reasoning**.  
The goal is to enhance the model‚Äôs **clinical reasoning**, **diagnostic interpretation**, and **chain-of-thought (CoT)** capabilities on complex medical cases.

---

## üß† Project Overview

This fine-tuned model is designed to:
- Understand **clinical case questions**
- Generate **step-by-step reasoning** (Chain of Thought)
- Produce **accurate diagnostic and pathophysiological explanations**

It was trained using the **FreedomIntelligence/medical-o1-reasoning-SFT** dataset and optimized through **LoRA fine-tuning** (Low-Rank Adaptation) on **DeepSeek-R1-Distill-Llama-8B** via **Unsloth**.

---

## ‚öôÔ∏è Model Details

| Parameter | Value |
|------------|--------|
| **Base Model** | DeepSeek-R1-Distill-Llama-8B |
| **Fine-tuning Framework** | [Unsloth](https://github.com/unslothai/unsloth) |
| **Technique** | LoRA (Low-Rank Adaptation) |
| **Precision** | 4-bit quantization |
| **Dataset** | [FreedomIntelligence/medical-o1-reasoning-SFT](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT) |
| **Training Examples** | 5,000 |
| **Epochs** | 10 |
| **Hardware** | Google Colab (A100 GPU) |
| **Tracked With** | Weights & Biases (wandb) |

---

## ü§ó Pretrained Model

You can directly download and use the fine-tuned model from Hugging Face:

üîó **[ali8461/fine-tuned-medical-model_5000_rows_10_epochs](https://huggingface.co/ali8461/fine-tuned-medical-model_5000_rows_10_epochs)**

### Example ‚Äî Load the Fine-Tuned Model

```python
from unsloth import FastLanguageModel
from transformers import AutoTokenizer
import torch

# Load model and tokenizer
model_name = "ali8461/fine-tuned-medical-model_5000_rows_10_epochs"
model, tokenizer = FastLanguageModel.from_pretrained(model_name, load_in_4bit=True)

# Prompt style
prompt = """Below is a medical question. Think step-by-step before answering.

### Question:
A 35-year-old man presents with chest pain radiating to the left arm and elevated troponin levels. What is the most likely diagnosis?

### Response:
<think>"""

# Generate reasoning and answer
inputs = tokenizer([prompt], return_tensors="pt").to("cuda")
outputs = model.generate(input_ids=inputs.input_ids, max_new_tokens=500)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
````

---

## üìä Training and Learning Curves

The model was trained for **10 epochs** with continuous monitoring via **Weights & Biases (wandb)**.

### üß© Learning Curve

*(Replace this with your actual plot image)*

![Learning Curve](results/learning_curve.png)

> Example: Training loss vs. steps showing convergence during LoRA fine-tuning.

---

## üß™ Test Results

Below are sample test cases illustrating the model‚Äôs reasoning ability after fine-tuning.

---

### ü©∫ **Case 1**

**Question:**
A 26-year-old breastfeeding woman presents with redness, pain around the nipple, and purulent discharge, with a culture showing *Staphylococcus aureus*. Describe a typical occurrence pattern of this condition during the breastfeeding period.

**Response:**
The condition described is **mastitis**, which often occurs during the **early postpartum period**, particularly when milk production increases and the breasts are undergoing significant changes.
Mastitis is characterized by inflammation of breast tissue with **redness, pain, and purulent discharge**, commonly caused by *Staphylococcus aureus*.

This condition is frequent among breastfeeding mothers due to **blocked milk ducts** or **nipple injury**, allowing bacterial entry into breast tissue. Early recognition and treatment are essential to prevent complications.
Management includes **rest, warm compresses, antibiotics**, and continued breastfeeding as tolerated.

---

### ü©∫ **Case 2**

**Question:**
A 59-year-old man presents with a fever, chills, night sweats, and generalized fatigue, and is found to have a 12 mm vegetation on the aortic valve. Blood cultures indicate gram-positive, catalase-negative, gamma-hemolytic cocci in chains that do not grow in a 6.5% NaCl medium.
What is the most likely predisposing factor for this patient's condition?

**Response:**
The findings indicate **infective endocarditis** caused by *Streptococcus gallolyticus* (formerly *S. bovis*).
The **most likely predisposing factor** is a **gastrointestinal lesion or trauma**, particularly **colonic neoplasia** or **mucosal injury**, which allows bacterial translocation into the bloodstream.
This association highlights the importance of **colonoscopy screening** in patients with *S. gallolyticus* endocarditis.

---

## üñºÔ∏è Visualization Results


`results/learning_curve.png`

---

## üìÅ Repository Structure

```
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ learning_curve.png
‚îÇ   ‚îú‚îÄ‚îÄ example_generation.png
‚îú‚îÄ‚îÄ README.md
```

> Note: The **training code and dataset** are not uploaded, but full details and model link are provided above.

---

## üß∞ Dependencies (used in Colab)

| Library         | Version              |
| --------------- | -------------------- |
| Python          | ‚â•3.9                 |
| PyTorch         | ‚â•2.3.0               |
| Unsloth         | Latest (from GitHub) |
| Transformers    | ‚â•4.44.0              |
| Datasets        | ‚â•2.20.0              |
| TRL             | ‚â•0.9.0               |
| huggingface_hub | ‚â•0.24.0              |
| wandb           | ‚â•0.17.0              |

---

## üë®‚Äç‚öïÔ∏è Author

**Ali** ‚Äî AI and Data Engineer

* ü§ó [Hugging Face Profile](https://huggingface.co/ali8461)
* üíª [GitHub Profile](https://github.com/ali8461)

---

## üßæ License

This project is shared under the **MIT License**.
You are free to use and modify the model for research and educational purposes.

---

## üåü Acknowledgements

* [Unsloth](https://github.com/unslothai/unsloth) ‚Äî Efficient fine-tuning of LLMs
* [FreedomIntelligence/medical-o1-reasoning-SFT](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT) ‚Äî Medical CoT dataset
* [DeepSeek AI](https://huggingface.co/deepseek-ai) ‚Äî Base model provider
* [Hugging Face Hub](https://huggingface.co/) ‚Äî Model hosting

---

> üß† *This project advances the integration of medical expertise and reasoning into large language models, supporting explainable clinical decision-making.*
